{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/soumyaparvatikar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/soumyaparvatikar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "#\n",
    "# you may need to run the following\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# Location = r'/Users/soumyaparvatikar/JupyterProjects/hw1/censusData.csv'\n",
    "Location = r'/Users/soumyaparvatikar/Desktop/project_dataset/train.csv'\n",
    "df = pd.read_csv(Location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0005300084f90edc</td>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00054a5e18b50dd4</td>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0006f16e4e9f292e</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "0   0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1   000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2   000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3   0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4   0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "5   00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7   00031b1e95af7921  Your vandalism to the Matt Shirvington article...   \n",
       "8   00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n",
       "9   00040093b2687caa  alignment on this subject and which are contra...   \n",
       "10  0005300084f90edc  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...   \n",
       "11  00054a5e18b50dd4  bbq \\n\\nbe a man and lets discuss it-maybe ove...   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "13  0006f16e4e9f292e  Before you start throwing accusations and warn...   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0       0             0        0       0       0              0  \n",
       "1       0             0        0       0       0              0  \n",
       "2       0             0        0       0       0              0  \n",
       "3       0             0        0       0       0              0  \n",
       "4       0             0        0       0       0              0  \n",
       "5       0             0        0       0       0              0  \n",
       "6       1             1        1       0       1              0  \n",
       "7       0             0        0       0       0              0  \n",
       "8       0             0        0       0       0              0  \n",
       "9       0             0        0       0       0              0  \n",
       "10      0             0        0       0       0              0  \n",
       "11      0             0        0       0       0              0  \n",
       "12      1             0        0       0       0              0  \n",
       "13      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a row for clean comment\n",
    "df['clean'] = None\n",
    "vec = []\n",
    "for i, row in df.iterrows():\n",
    "    if((row['toxic'] == 1) or (row['severe_toxic'] == 1) or (row['obscene'] == 1) or (row['threat'] == 1) or (row['insult'] == 1) or (row['identity_hate'] == 1)):\n",
    "        vec.append(0)\n",
    "    else:\n",
    "        vec.append(1)\n",
    "df['clean'] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  clean  \n",
       "0             0        0       0       0              0      1  \n",
       "1             0        0       0       0              0      1  \n",
       "2             0        0       0       0              0      1  \n",
       "3             0        0       0       0              0      1  \n",
       "4             0        0       0       0              0      1  \n",
       "5             0        0       0       0              0      1  \n",
       "6             1        1       0       1              0      0  \n",
       "7             0        0       0       0              0      1  \n",
       "8             0        0       0       0              0      1  \n",
       "9             0        0       0       0              0      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate          clean  \n",
       "count  159571.000000  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805       0.898321  \n",
       "std         0.216627       0.093420       0.302226  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming and tokenizing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#\n",
    "#  Input : dataframe with a column names 'text' which contains raw tweets (one per row)\n",
    "#  Output: A list of lists of tokens corrsponding to the 'text' column\n",
    "#\n",
    "def tokenize_tweets(df):\n",
    "    \"\"\"Given a df with tweets in 'text' col, this function return tokens as a list of lists\"\"\"\n",
    "\n",
    "    # apply tokenize to the 'text' coolumn in the tweets df\n",
    "    tweet_tokenizer = nltk.tokenize.TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "    tokens = df['comment_text'].apply(tweet_tokenizer.tokenize)\n",
    "    \n",
    "    # filter\n",
    "    misc = ['’', '…', '—', '\"', 'w', '...', '️', 'http', 'https', '(', ')', '.','|', ',']\n",
    "#     to_remove = nltk.corpus.stopwords.words('English') + list(string.punctuation) + misc\n",
    "#     to_remove = misc\n",
    "    to_remove = []\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # [[a,bird,flew], [high, main, france, the]] => [[bird,fly],[high,france,main]]\n",
    "    tokens = [[lemmatizer.lemmatize(token) for token in tw if token not in to_remove] for tw in tokens]      \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"',\n",
       " 'congratulation',\n",
       " 'from',\n",
       " 'me',\n",
       " 'a',\n",
       " 'well',\n",
       " ',',\n",
       " 'use',\n",
       " 'the',\n",
       " 'tool',\n",
       " 'well',\n",
       " '.',\n",
       " '·',\n",
       " 'talk',\n",
       " '\"']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = tokenize_tweets(df)\n",
    "all_tokens[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEmptyComments(all_tokens, dframe):\n",
    "    unwanted_indices = []\n",
    "    desired_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for idx, i in enumerate(all_tokens):  \n",
    "        if len(i) == 0:\n",
    "            count = count + 1\n",
    "            unwanted_indices.append(idx)\n",
    "#             df.drop(df.index[idx], inplace=True)\n",
    "        else:\n",
    "            filtered_tokens.append(i)\n",
    "#             df = df.append(i)\n",
    "    \n",
    "    desired_indices = [j for j in dframe.index if j not in unwanted_indices]\n",
    "    desired_df = dframe.iloc[desired_indices]\n",
    "    desired_df = desired_df.reset_index(drop = True)\n",
    "    print(count) \n",
    "    return filtered_tokens, desired_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[['explanation', 'why', 'the', 'edits', 'made', 'under', 'my', 'username', 'hardcore', 'metallica', 'fan', 'were', 'reverted', '?', 'they', \"weren't\", 'vandalism', ',', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'doll', 'fac', '.', 'and', 'please', \"don't\", 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', \"i'm\", 'retired', 'now', '.', '89.205', '.', '38.27'], [\"d'aww\", '!', 'he', 'match', 'this', 'background', 'colour', \"i'm\", 'seemingly', 'stuck', 'with', '.', 'thanks', '.', '(', 'talk', ')', '21:51', ',', 'january', '11', ',', '2016', '(', 'utc', ')'], ['hey', 'man', ',', \"i'm\", 'really', 'not', 'trying', 'to', 'edit', 'war', '.', \"it's\", 'just', 'that', 'this', 'guy', 'is', 'constantly', 'removing', 'relevant', 'information', 'and', 'talking', 'to', 'me', 'through', 'edits', 'instead', 'of', 'my', 'talk', 'page', '.', 'he', 'seems', 'to', 'care', 'more', 'about', 'the', 'formatting', 'than', 'the', 'actual', 'info', '.']]\n"
     ]
    }
   ],
   "source": [
    "# remove empty comments\n",
    "filtered_tokens, desired_df = removeEmptyComments(all_tokens, df)\n",
    "print(filtered_tokens[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Set\n",
    "\n",
    "def separateValidationSet(filtered_tokens, dframe):\n",
    "    trainDF = pd.DataFrame()\n",
    "    validationDF = pd.DataFrame()\n",
    "    validation_indices = []\n",
    "    train_indices = []\n",
    "    validationSet = []\n",
    "    trainSet = []\n",
    "    for idx, i in enumerate(filtered_tokens):\n",
    "        if (idx%10 <= 2):\n",
    "            validationSet.append(i)\n",
    "            validation_indices.append(idx)\n",
    "        else:\n",
    "            trainSet.append(i)\n",
    "            train_indices.append(idx)\n",
    "    \n",
    "#     trainDF_indices = [j for j in dframe.index if j in validation_indices]\n",
    "#     trainDF = dframe.iloc[trainDF_indices]\n",
    "    trainDF = dframe.iloc[train_indices]\n",
    "    trainDF = trainDF.reset_index(drop = True) \n",
    "    \n",
    "    validationDF = dframe.iloc[validation_indices]\n",
    "    validationDF = validationDF.reset_index(drop = True)\n",
    "    \n",
    "    return trainSet, validationSet, trainDF, validationDF\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet_tokens, validationSet_tokens, trainDF, validationDF = separateValidationSet(filtered_tokens, desired_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "# calculate the frequency of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "newArray = []\n",
    "newArray = [' '.join(i) for i in trainSet_tokens ]\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=5, max_features=15000, ngram_range=(1, 2))  \n",
    "counts_train = count_vect.fit_transform(newArray)\n",
    "print(len(count_vect.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the TFID score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer().fit(counts_train)\n",
    "\n",
    "counts_train = transformer.transform(counts_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "newArray_validation = []\n",
    "# newArray = top_words.apply(lambda x: ' '.join(x))\n",
    "newArray_validation = [' '.join(i) for i in validationSet_tokens ]\n",
    "\n",
    "print(len(count_vect.get_feature_names()))\n",
    "\n",
    "counts_validation = count_vect.transform(newArray_validation)\n",
    "\n",
    "counts_validation = transformer.transform(counts_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for validation set\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = {}\n",
    "\n",
    "for i in range(1,8):\n",
    "    y_train=trainDF.iloc[:,i+1].values \n",
    "    model[i] = MultinomialNB(alpha=1, fit_prior=True, class_prior=None).fit(counts_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9515483576397282\n",
      "(0.7623997623997624, 0.7188462615513862, 0.7399827039492648, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9906355473191345\n",
      "(0.5439642324888226, 0.33031674208144796, 0.411036036036036, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9739209840732683\n",
      "(0.7854158754272693, 0.6987666835614124, 0.73956191327671, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9970098210368938\n",
      "(0.5882352941176471, 0.02967359050445104, 0.05649717514124293, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9704205051074763\n",
      "(0.7253521126760564, 0.6502525252525253, 0.685752330226365, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9912085157432027\n",
      "(0.5260663507109005, 0.11178247734138973, 0.18438538205980068, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9420496154844716\n",
      "(0.9407803283615734, 0.9983255424544757, 0.968699074947171, None)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# prediction for train set\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "for i in range(1,8):\n",
    "    y_train=trainDF.iloc[:,i+1].values\n",
    "    y_validation = validationDF.iloc[:,i+1].values\n",
    "#     predicted = model[i].predict(counts_train)\n",
    "    predicted = (model[i].predict_proba(counts_train)[:,1] >= 0.3).astype(bool)\n",
    "    \n",
    "    print(\"accuracy: \", np.mean(predicted == y_train))\n",
    "    print(precision_recall_fscore_support(y_train, predicted, average='binary'))\n",
    "    print(\"----------------------------------------------\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9478191844919787\n",
      "(0.7503004085556356, 0.6815105872080331, 0.714253031342942, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9902657085561497\n",
      "(0.5431654676258992, 0.3081632653061224, 0.3932291666666667, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9724264705882353\n",
      "(0.7790590405904059, 0.6675889328063241, 0.7190293742017881, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9970755347593583\n",
      "(0.6666666666666666, 0.014184397163120567, 0.027777777777777776, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.969167780748663\n",
      "(0.7122337790985637, 0.6163737676810973, 0.6608455882352942, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9912057152406417\n",
      "(0.44, 0.08009708737864078, 0.135523613963039, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9397142379679144\n",
      "(0.9385970664743043, 0.9982099267697315, 0.9674860863883193, None)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# prediction for validation set\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "for i in range(1,8):\n",
    "    y_validation = validationDF.iloc[:,i+1].values    \n",
    "#     predicted = model[i].predict(counts_validation)\n",
    "    predicted = (model[i].predict_proba(counts_validation)[:,1] >= 0.3).astype(bool)\n",
    "    \n",
    "    print(\"accuracy: \", np.mean(predicted == y_validation))\n",
    "    print(precision_recall_fscore_support(y_validation, predicted, average='binary'))\n",
    "    print(\"----------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "# merge train and validation and run again\n",
    "newArray_complete = []\n",
    "newArray_complete = [' '.join(i) for i in filtered_tokens ]\n",
    "\n",
    "count_vect_complete = CountVectorizer(max_df=0.8, min_df=5, max_features=15000, ngram_range=(1, 2))  \n",
    "counts_train_complete = count_vect_complete.fit_transform(newArray_complete)\n",
    "print(len(count_vect_complete.get_feature_names()))\n",
    "# -------------------------------------------------\n",
    "\n",
    "transformer_complete = TfidfTransformer().fit(counts_train_complete)\n",
    "\n",
    "counts_train_complete = transformer_complete.transform(counts_train_complete) \n",
    "# -------------------------------------------------\n",
    "\n",
    "model_complete = {}\n",
    "\n",
    "for i in range(1,8):\n",
    "    y_train_complete=desired_df.iloc[:,i+1].values \n",
    "    model_complete[i] = MultinomialNB(alpha=1, fit_prior=True, class_prior=None).fit(counts_train_complete, y_train_complete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loc_test = r'/Users/soumyaparvatikar/Desktop/project_dataset/test.csv'\n",
    "df_test = pd.read_csv(Loc_test)\n",
    "\n",
    "Loc_test_label = r'/Users/soumyaparvatikar/Desktop/project_dataset/test_labels.csv'\n",
    "df_test_label = pd.read_csv(Loc_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               63978\n",
      "toxic            63978\n",
      "severe_toxic     63978\n",
      "obscene          63978\n",
      "threat           63978\n",
      "insult           63978\n",
      "identity_hate    63978\n",
      "dtype: int64\n",
      "id              63978\n",
      "comment_text    63978\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test_label_clean = df_test_label[df_test_label['toxic'] != -1]\n",
    "df_test_clean = df_test[df_test_label['toxic'] != -1]\n",
    "df_test_label_clean.count()\n",
    "print(df_test_label_clean.count())\n",
    "print(df_test_clean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumyaparvatikar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/soumyaparvatikar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# add a row for clean comment\n",
    "df_test_label_clean['clean'] = None\n",
    "temp_vec = []\n",
    "for i, row in df_test_label_clean.iterrows():\n",
    "    if((row['toxic'] == 1) or (row['severe_toxic'] == 1) or (row['obscene'] == 1) or (row['threat'] == 1) or (row['insult'] == 1) or (row['identity_hate'] == 1)):\n",
    "        temp_vec.append(0)\n",
    "    else:\n",
    "        temp_vec.append(1)\n",
    "df_test_label_clean['clean'] = temp_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571\n",
      "id               63978\n",
      "toxic            63978\n",
      "severe_toxic     63978\n",
      "obscene          63978\n",
      "threat           63978\n",
      "insult           63978\n",
      "identity_hate    63978\n",
      "clean            63978\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(vec))\n",
    "print(df_test_label_clean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"',\n",
       " ':',\n",
       " 'maybe',\n",
       " 'one',\n",
       " 'of',\n",
       " 'these',\n",
       " 'day',\n",
       " '.',\n",
       " 'cool',\n",
       " 'random',\n",
       " 'quote',\n",
       " ',',\n",
       " 'by',\n",
       " 'the',\n",
       " 'way',\n",
       " ',',\n",
       " 'at',\n",
       " '.',\n",
       " '\"',\n",
       " '\"',\n",
       " 'like',\n",
       " '\"',\n",
       " '\"',\n",
       " 'you',\n",
       " 'fucking',\n",
       " 'breeder',\n",
       " ',',\n",
       " 'why',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'fuck',\n",
       " 'your',\n",
       " 'own',\n",
       " 'sex',\n",
       " '?',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_test = tokenize_tweets(df_test_clean)\n",
    "all_tokens_test[228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63978\n",
      "id              63978\n",
      "comment_text    63978\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(all_tokens_test))\n",
    "print(df_test_clean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "newArray_test = []\n",
    "newArray_test = [' '.join(i) for i in all_tokens_test ]\n",
    "\n",
    "print(len(count_vect_complete.get_feature_names()))\n",
    "\n",
    "counts_test = count_vect_complete.transform(newArray_test)\n",
    "\n",
    "counts_test = transformer_complete.transform(counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 9)\n",
      "(63978, 8)\n",
      "6090\n",
      "57888\n",
      "accuracy:  0.9201913157647942\n",
      "(0.5642969158389963, 0.7090311986863711, 0.6284383641391356, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9910281659320391\n",
      "(0.29504950495049503, 0.40599455040871935, 0.34174311926605505, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9553752852543062\n",
      "(0.6071245515120451, 0.6418314819832024, 0.6239957855919925, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9966863609365719\n",
      "(0.4444444444444444, 0.018957345971563982, 0.03636363636363637, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9539060301978806\n",
      "(0.5672481710748453, 0.588269623577473, 0.5775676837129351, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9893713464003251\n",
      "(0.5666666666666667, 0.19101123595505617, 0.2857142857142857, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9353684078902123\n",
      "(0.9434589800443459, 0.9875638694033082, 0.965007743147526, None)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test results\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "print(desired_df.shape)\n",
    "print(df_test_label_clean.shape)\n",
    "\n",
    "print(sum(df_test_label_clean['toxic'] == 1))\n",
    "print(sum(df_test_label_clean['toxic'] == 0))\n",
    "\n",
    "# changes\n",
    "for i in range(1,8):\n",
    "#     y_train=desired_df.iloc[:,i+1].values\n",
    "    y_test = df_test_label_clean.iloc[:,i].values\n",
    "\n",
    "    # use the tfid score as x_train to train the model\n",
    "    # changes\n",
    "#     model = MultinomialNB(alpha=0, fit_prior=True, class_prior=None).fit(counts, y_train)\n",
    "#     predicted = model.predict(counts_test)\n",
    "    predicted = (model_complete[i].predict_proba(counts_test)[:,1] >= 0.3).astype(bool)\n",
    "    print(\"accuracy: \", np.mean(predicted == y_test)) \n",
    "    print(precision_recall_fscore_support(y_test, predicted, average='binary'))\n",
    "    print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9613604419018971\n",
      "(0.9396563573883161, 0.6381032390553533, 0.7600622637313763, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9913338525859676\n",
      "(0.6532438478747203, 0.2642533936651584, 0.3762886597938144, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9789255051522395\n",
      "(0.9342265529841657, 0.6479134989018416, 0.7651636073423782, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9972694473540498\n",
      "(0.7962962962962963, 0.12759643916913946, 0.21994884910485935, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9742611840750589\n",
      "(0.8716235032024505, 0.5645743145743146, 0.6852764094143404, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9924439789075999\n",
      "(0.7811320754716982, 0.2084592145015106, 0.329093799682035, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9604293682127861\n",
      "(0.9613723169875218, 0.9959633612741825, 0.9783621837549934, None)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# logistic regression for training set\n",
    "# Training set was evaluated only to compare the results with validation set and get a sense for overfitting.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = {}\n",
    "\n",
    "for i in range(1,8):    \n",
    "    y_train=trainDF.iloc[:,i+1].values \n",
    "    logreg[i] = LogisticRegression()\n",
    "    logreg[i].fit(counts_train, y_train)\n",
    "    lr_prediction = logreg[i].predict(counts_train)\n",
    "    print(\"accuracy: \", np.mean(lr_prediction == y_train))\n",
    "    print(precision_recall_fscore_support(y_train, lr_prediction, average='binary'))\n",
    "    print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9567179144385026\n",
      "(0.9228176609369734, 0.5976860947391399, 0.7254901960784313, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9903283756684492\n",
      "(0.5721925133689839, 0.21836734693877552, 0.3161004431314623, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9770429478609626\n",
      "(0.9181765049678551, 0.6209486166007905, 0.7408630040084885, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.997305314171123\n",
      "(0.7307692307692307, 0.1347517730496454, 0.2275449101796407, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9718833556149733\n",
      "(0.831876260928043, 0.5302186026575225, 0.6476439790575916, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9925635026737968\n",
      "(0.7745098039215687, 0.19174757281553398, 0.30739299610894943, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9556525735294118\n",
      "(0.9572208059394427, 0.9951179820992677, 0.9758015797932363, None)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# logistic regression for validation\n",
    "\n",
    "for i in range(1,8):\n",
    "    y_validation = validationDF.iloc[:,i+1].values \n",
    "#     logreg = LogisticRegression()\n",
    "#     logreg.fit(counts_validation, y_validation)\n",
    "    prediction = logreg[i].predict(counts_validation)\n",
    "    print(\"accuracy: \", np.mean(prediction == y_validation))\n",
    "    print(precision_recall_fscore_support(y_validation, prediction, average='binary'))\n",
    "    print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    }
   ],
   "source": [
    "# merge train and validation and run again\n",
    "newArray_complete = []\n",
    "newArray_complete = [' '.join(i) for i in filtered_tokens ]\n",
    "\n",
    "count_vect_complete = CountVectorizer(max_df=0.8, min_df=5, max_features=150000, ngram_range=(1, 2))  \n",
    "counts_train_complete = count_vect_complete.fit_transform(newArray_complete)\n",
    "print(len(count_vect_complete.get_feature_names()))\n",
    "# -------------------------------------------------\n",
    "\n",
    "transformer_complete = TfidfTransformer().fit(counts_train_complete)\n",
    "\n",
    "counts_train_complete = transformer_complete.transform(counts_train_complete) \n",
    "# -------------------------------------------------\n",
    "\n",
    "logreg_complete = {}\n",
    "\n",
    "for i in range(1,8):    \n",
    "    y_train_complete=desired_df.iloc[:,i+1].values \n",
    "    logreg_complete[i] = LogisticRegression(C=1.85, penalty='l1')\n",
    "    logreg_complete[i].fit(counts_train_complete, y_train_complete)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    }
   ],
   "source": [
    "newArray_test = []\n",
    "# newArray = top_words.apply(lambda x: ' '.join(x))\n",
    "newArray_test = [' '.join(i) for i in all_tokens_test ]\n",
    "\n",
    "print(len(count_vect_complete.get_feature_names()))\n",
    "\n",
    "counts_test = count_vect_complete.transform(newArray_test)\n",
    "\n",
    "counts_test = transformer_complete.transform(counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 9)\n",
      "(63978, 8)\n",
      "6090\n",
      "57888\n",
      "accuracy:  0.9292725624433399\n",
      "(0.5956952427540663, 0.7998357963875206, 0.682834513212308, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9924974209884648\n",
      "(0.36253041362530414, 0.40599455040871935, 0.3830334190231362, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9648472912563694\n",
      "(0.6924719701014416, 0.7027905716607965, 0.6975931155035633, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9965613179530464\n",
      "(0.47398843930635837, 0.3886255924170616, 0.42708333333333337, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9647378786457845\n",
      "(0.7037939436129481, 0.5900204260285964, 0.6419047619047619, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.990418581387352\n",
      "(0.6073752711496746, 0.39325842696629215, 0.47740835464620635, None)\n",
      "----------------------------------------------\n",
      "accuracy:  0.9240207571352652\n",
      "(0.9808475809385231, 0.9340434744955399, 0.9568735305859912, None)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test results for Logistic regression\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "print(desired_df.shape)\n",
    "print(df_test_label_clean.shape)\n",
    "\n",
    "print(sum(df_test_label_clean['toxic'] == 1))\n",
    "print(sum(df_test_label_clean['toxic'] == 0))\n",
    "\n",
    "for i in range(1,8):\n",
    "#     y_train=desired_df.iloc[:,i+1].values\n",
    "    y_test = df_test_label_clean.iloc[:,i].values\n",
    "\n",
    "    prediction = logreg_complete[i].predict(counts_test)\n",
    "\n",
    "    print(\"accuracy: \", np.mean(prediction == y_test)) \n",
    "    print(precision_recall_fscore_support(y_test, prediction, average='binary'))\n",
    "    print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
